# Multi-Experiment Configuration for LongCTR Models
# This config defines combinations of datasets, models, and max_user_seq_len values

# Experiment combinations
dataset_list:

# Redkiwi dataset
  - redkiwi32
  - redkiwi64
  - redkiwi128
  - alipay
  - tmall
  - taobao # CUDA error가 나는 데 확인이 필요함 -> 지금은 됨 (2026.01.03)
  - amazon
  # - taobaodmr # -> shape 오류남 (2026.01.03)



model_list:
  - mirrn
  - twin
  - sdim
  - eta
  - sim
  - dcnv2
  - dien
  - din
  - finalmlp
  - transact
  - odpp

max_user_seq_len_list: 
  - 96
  - 192
  - 336
  - 720

# Path templates
data_root_template: "../../data/{dataset_name}/maxlen{max_user_seq_len}/"
results_root_template: "./results/{dataset_name}/{max_user_seq_len}/"

# Base configs for each model
model_base_configs:
  dcnv2:
    base_config: "./config/dcnv2_config/"
    base_expid: "DCNv2_default"
  dien:
    base_config: "./config/dien_config/"
    base_expid: "DIEN_default"
  din:
    base_config: "./config/din_config/"
    base_expid: "DIN_default"
  finalmlp:
    base_config: "./config/finalmlp_config/"
    base_expid: "FinalMLP_default"
  transact:
    base_config: "./config/transact_config/"
    base_expid: "TransAct_default"
  mirrn:
    base_config: "./config/mirrn_config/"
    base_expid: "MIRRN_default"
  twin:
    base_config: "./config/twin_config/"
    base_expid: "TWIN_default"
  sdim:
    base_config: "./config/sdim_config/"
    base_expid: "SDIM_default"
  sim:
    base_config: "./config/sim_config/"
    base_expid: "SIM_default"
  eta:
    base_config: "./config/eta_config/"
    base_expid: "ETA_default"
  odpp:
    base_config: "./config/odpp_config/"
    base_expid: "ODPP_default"

# Dataset-specific feature columns (shared across all max_seq_len)
datasets:
  redkiwi1:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi2:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi4:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi8:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi16:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi32:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi64:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi128:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi256:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi512:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}  
  redkiwi1024:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi2048:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi4096:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}

  alipay:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 529167}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 2060823}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 2060823}
    label_col: {name: label, dtype: float}

  tmall:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 422633}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 1025335}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 1025335}
    label_col: {name: label, dtype: float}

  taobao:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 982583}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 4022483}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 4022483}
    label_col: {name: label, dtype: float}
    
  amazon:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 192403}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 62943}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 62943}
    label_col: {name: label, dtype: float}

  taobaodmr:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
        - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 1055077}
        - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 12140}
        - {name: seq_len, active: True, dtype: int, type: meta}
        - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 12140}
    label_col: {name: label, dtype: float}
      


# Hyperparameter search space per model
tuner_spaces:
  # example_mirrn:
  #   model_root: './checkpoints/'
  #   embedding_dim: [32]
  #   dnn_hidden_units: [[512, 256, 128]]
  #   net_dropout: [0.1]
  #   batch_norm: False
  #   learning_rate: [1.e-3]
  #   batch_size: 256
  #   epochs : 2
  #   seed: 2025
  #   metrics: [[PRAUC, AUC, logloss]]
  #   monitor: {"PRAUC": 1} 
  #   # Imbalanced data handling
  #   use_pos_weight: True  # Auto calculate pos_weight (neg/pos) for BCE loss
  #   # train_sampling: ["undersampling"]  # null, "oversampling", "undersampling"
  #   # train_sampling_ratio: 1.0  # Target ratio for oversampling/undersampling

  dcnv2:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    stacked_dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    parallel_dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    num_cross_layers: [2, 3, 4]
    net_dropout: [0, 0.1, 0.2]
    model_structure: [parallel, stacked]
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  dien:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    gru_type: [AUGRU, GRU]
    dnn_activations: Dice
    attention_type: bilinear_attention
    attention_hidden_units: [80, 40]
    aux_hidden_units: [100, 50]
    batch_norm: True
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  din:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    attention_hidden_units: [[64], [128]]
    attention_hidden_activations: "Dice"
    din_use_softmax: False
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  finalmlp:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    mlp1_hidden_units: [[256, 128], [512, 256]]
    mlp2_hidden_units: [[256, 128, 64], [512, 256, 128]]
    mlp1_dropout: [0, 0.1, 0.2]
    mlp2_dropout: [0, 0.1, 0.2]
    num_heads: [2, 4]
    use_fs: True
    fs_hidden_units: [[256, 128], [512, 256]]
    mlp1_batch_norm: False
    mlp2_batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  transact:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dcn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    num_heads: [2, 4]
    transformer_layers: [1, 2]
    transformer_dropout: [0, 0.1, 0.2]
    net_dropout: [0, 0.1, 0.2]
    dcn_cross_layers: 3
    dim_feedforward: [128, 256]
    concat_max_pool: True
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  mirrn:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    attention_dim: [32, 64, 128]
    num_heads: [2, 4]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    topk: [20, 50, 100]
    short_seq_len: [10, 20]
    hash_bits: [16, 32]
    use_scale: True
    reuse_hash: True
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  twin:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    attention_dim: [32, 64, 128]
    num_heads: [2, 4]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    topk: [20, 50, 100]
    short_seq_len: [10, 20]
    Kc_cross_features: 0
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  sdim:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    attention_dim: [32, 64, 128]
    num_heads: [2, 4]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    num_hashes: [1, 2]
    hash_bits: [4, 8]
    short_seq_len: [10, 20]
    use_qkvo: True
    use_scale: True
    reuse_hash: True
    l2_norm: False
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  eta:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    attention_dim: [32, 64, 128]
    num_heads: [2, 4]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    topk: [20, 50, 100]
    short_seq_len: [10, 20]
    hash_bits: [16, 32]
    use_scale: True
    reuse_hash: True
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

  sim:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    attention_dim: [32, 64, 128]
    num_heads: [2, 4]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    topk: [20, 50, 100]
    short_seq_len: [10, 20]
    gsu_type: ["soft", "hard"]
    alpha: 1
    beta: 1
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  
  
  odpp:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    seg_len: [10, 20, 30]
    top_k: [5, 10, 20]
    dist_hidden_dim: [32, 64]
    dist_output_dim: [64, 128]
    pos_hidden_dim: [32, 64]
    pos_output_dim: [32, 64, 128]
    fusion_output_dim: [64, 128, 256]
    dnn_activations: relu
    use_distribution_encoder: [True, False]
    use_position_pooling: [True, False]
    net_dropout: 0
    accumulation_steps: 1
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 256
    epochs: 50
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {'PRAUC': 1, 'logloss': -1}
    use_pos_weight: True  

# GPU settings
gpu_list: [0] # , 1, 2, 3, 4, 5, 6, 7
