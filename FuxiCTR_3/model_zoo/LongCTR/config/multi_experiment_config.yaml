# Multi-Experiment Configuration for LongCTR Models
# This config defines combinations of datasets, models, and max_user_seq_len values

# Experiment combinations
dataset_list:

# Redkiwi dataset
  # - redkiwi1
  # - redkiwi2
  # - redkiwi4
  # - redkiwi8
  # - redkiwi16
  - redkiwi32
  # - redkiwi64
  # - redkiwi128
  # - redkiwi256
  # - redkiwi512
  # - redkiwi1024
  # - redkiwi2048
  # - redkiwi4096
  
  # - alipay
  # - tmall
  # - taobao # CUDA error가 나는 데 확인이 필요함 -> 지금은 됨 (2026.01.03)
  # - amazon
  # - taobaodmr # -> shape 오류남 (2026.01.03)



model_list:
  - mirrn
  # - twin
  # - sdim
  # - eta
  # - sim

max_user_seq_len_list:
  # - 64
  # - 128
  # - 256
  # - 512
  - 1024
  # - 2048
  # - 4096
  # - 8192

# Path templates
data_root_template: "../../data/{dataset_name}/maxlen{max_user_seq_len}/"
results_root_template: "./results/{dataset_name}/{max_user_seq_len}/"

# Base configs for each model
model_base_configs:
  dcnv2:
    base_config: "./config/dcnv2_config/"
    base_expid: "DCNv2_default"
  dien:
    base_config: "./config/dien_config/"
    base_expid: "DIEN_default"
  din:
    base_config: "./config/din_config/"
    base_expid: "DIN_default"
  finalmlp:
    base_config: "./config/finalmlp_config/"
    base_expid: "FinalMLP_default"
  transact:
    base_config: "./config/transact_config/"
    base_expid: "TransAct_default"
  mirrn:
    base_config: "./config/mirrn_config/"
    base_expid: "MIRRN_default"
  twin:
    base_config: "./config/twin_config/"
    base_expid: "TWIN_default"
  sdim:
    base_config: "./config/sdim_config/"
    base_expid: "SDIM_default"
  sim:
    base_config: "./config/sim_config/"
    base_expid: "SIM_default"
  eta:
    base_config: "./config/eta_config/"
    base_expid: "ETA_default"

# Dataset-specific feature columns (shared across all max_seq_len)
datasets:
  redkiwi1:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi2:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi4:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi8:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi16:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi32:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi64:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi128:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi256:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi512:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}  
  redkiwi1024:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi2048:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}
  redkiwi4096:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 84648}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 601}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 601}
    label_col: {name: label, dtype: float}

  alipay:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 529167}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 2060823}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 2060823}
    label_col: {name: label, dtype: float}

  tmall:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 422633}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 1025335}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 1025335}
    label_col: {name: label, dtype: float}

  taobao:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 982583}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 4022483}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 4022483}
    label_col: {name: label, dtype: float}
    
  amazon:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
      - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 192403}
      - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 62943}
      - {name: seq_len, active: True, dtype: int, type: meta}
      - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 62943}
    label_col: {name: label, dtype: float}

  taobaodmr:
    data_format: parquet
    rebuild_dataset: False
    feature_cols:
        - {name: user_index, active: True, dtype: int, type: meta, vocab_size: 1055077}
        - {name: item_index, active: True, dtype: int, type: meta, vocab_size: 12140}
        - {name: seq_len, active: True, dtype: int, type: meta}
        - {name: item_id, active: True, dtype: int, type: categorical, source: item, vocab_size: 12140}
    label_col: {name: label, dtype: float}
      


# Hyperparameter search space per model
tuner_spaces:
  # mirrn:
  #   model_root: './checkpoints/'
  #   embedding_dim: [32]
  #   dnn_hidden_units: [[512, 256, 128]]
  #   net_dropout: [0.1]
  #   batch_norm: False
  #   learning_rate: [1.e-3]
  #   batch_size: 2048
  #   epochs : 2
  #   seed: 2025
  #   metrics: [[PRAUC, AUC, logloss]]
  #   monitor: {"PRAUC": 1} 
  #   # Imbalanced data handling
  #   use_pos_weight: True  # Auto calculate pos_weight (neg/pos) for BCE loss
  #   # train_sampling: ["undersampling"]  # null, "oversampling", "undersampling"
  #   # train_sampling_ratio: 1.0  # Target ratio for oversampling/undersampling

  mirrn:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    attention_dim: [32, 64, 128]
    num_heads: [2, 4]
    net_dropout: [0, 0.1, 0.2]
    attention_dropout: [0, 0.1, 0.2]
    topk: [20, 50, 100]
    short_seq_len: [10, 20]
    hash_bits: [16, 32]
    use_scale: True
    reuse_hash: True
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 2048
    epochs: 2
    seed: 42
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {"PRAUC": 1}

  twin:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    net_dropout: [0, 0.1, 0.2]
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 2048
    epochs : 100
    seed: 2025
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {"PRAUC": 1}

  sdim:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    net_dropout: [0, 0.1, 0.2]
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 2048
    epochs : 100
    seed: 2025
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {"PRAUC": 1}

  sim:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    net_dropout: [0, 0.1, 0.2]
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 2048
    epochs : 100
    seed: 2025
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {"PRAUC": 1}

  eta:
    model_root: './checkpoints/'
    embedding_dim: [16, 32]
    dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
    net_dropout: [0, 0.1, 0.2]
    batch_norm: False
    learning_rate: [1.e-3, 5.e-4]
    batch_size: 2048
    epochs : 100
    seed: 2025
    metrics: [[PRAUC, AUC, logloss]]
    monitor: {"PRAUC": 1}


# # Hyperparameter search space per model
# tuner_spaces:
#   dcnv2:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     stacked_dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     parallel_dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     num_cross_layers: [2, 3, 4]
#     net_dropout: [0, 0.1, 0.2]
#     model_structure: [parallel, stacked]
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   dien:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     net_dropout: [0, 0.1, 0.2]
#     attention_dropout: [0, 0.1, 0.2]
#     gru_type: [AUGRU, GRU]
#     dnn_activations: Dice
#     attention_type: bilinear_attention
#     attention_hidden_units: [80, 40]
#     aux_hidden_units: [100, 50]
#     batch_norm: True
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   din:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     net_dropout: [0, 0.1, 0.2]
#     attention_dropout: [0, 0.1, 0.2]
#     attention_hidden_units: [[64], [128]]
#     attention_hidden_activations: "Dice"
#     din_use_softmax: False
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   finalmlp:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     mlp1_hidden_units: [[256, 128], [512, 256]]
#     mlp2_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     mlp1_dropout: [0, 0.1, 0.2]
#     mlp2_dropout: [0, 0.1, 0.2]
#     num_heads: [2, 4]
#     use_fs: True
#     fs_hidden_units: [[256, 128], [512, 256]]
#     mlp1_batch_norm: False
#     mlp2_batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   transact:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dcn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     num_heads: [2, 4]
#     transformer_layers: [1, 2]
#     transformer_dropout: [0, 0.1, 0.2]
#     net_dropout: [0, 0.1, 0.2]
#     dcn_cross_layers: 3
#     dim_feedforward: [128, 256]
#     concat_max_pool: True
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   mirrn:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     attention_dim: [32, 64, 128]
#     num_heads: [2, 4]
#     net_dropout: [0, 0.1, 0.2]
#     attention_dropout: [0, 0.1, 0.2]
#     topk: [20, 50, 100]
#     short_seq_len: [10, 20]
#     hash_bits: [16, 32]
#     use_scale: True
#     reuse_hash: True
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   twin:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     attention_dim: [32, 64, 128]
#     num_heads: [2, 4]
#     net_dropout: [0, 0.1, 0.2]
#     attention_dropout: [0, 0.1, 0.2]
#     topk: [20, 50, 100]
#     short_seq_len: [10, 20]
#     Kc_cross_features: 0
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   sdim:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     attention_dim: [32, 64, 128]
#     num_heads: [2, 4]
#     net_dropout: [0, 0.1, 0.2]
#     attention_dropout: [0, 0.1, 0.2]
#     num_hashes: [1, 2]
#     hash_bits: [4, 8]
#     short_seq_len: [10, 20]
#     use_qkvo: True
#     use_scale: True
#     reuse_hash: True
#     l2_norm: False
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   eta:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     attention_dim: [32, 64, 128]
#     num_heads: [2, 4]
#     net_dropout: [0, 0.1, 0.2]
#     attention_dropout: [0, 0.1, 0.2]
#     topk: [20, 50, 100]
#     short_seq_len: [10, 20]
#     hash_bits: [16, 32]
#     use_scale: True
#     reuse_hash: True
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}

#   sim:
#     model_root: './checkpoints/'
#     embedding_dim: [16, 32]
#     dnn_hidden_units: [[256, 128, 64], [512, 256, 128]]
#     attention_dim: [32, 64, 128]
#     num_heads: [2, 4]
#     net_dropout: [0, 0.1, 0.2]
#     attention_dropout: [0, 0.1, 0.2]
#     topk: [20, 50, 100]
#     short_seq_len: [10, 20]
#     gsu_type: ["soft", "hard"]
#     alpha: 1
#     beta: 1
#     batch_norm: False
#     learning_rate: [1.e-3, 5.e-4]
#     batch_size: 2048
#     epochs: 100
#     seed: 42
#     metrics: [[PRAUC, AUC, logloss]]
#     monitor: {"PRAUC": 1}


# GPU settings
gpu_list: [0, 3]
